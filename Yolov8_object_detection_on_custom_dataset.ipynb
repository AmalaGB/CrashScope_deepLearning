{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "b1bb2281-f9e6-45af-fec4-f95ed2404792"
      },
      "outputs": [],
      "source": [
        "# !nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "506a6a19-22a5-415c-a02d-4e4d17dccf30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\asus\\Downloads\\CarDamage\\code\\model\\Dataset\\Dataset\\data\\images\\val\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install ultralytics==8.0.20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "b7e777a1-8a18-4be0-9812-0a7910f0c6c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.28  Python-3.12.0 torch-2.5.0+cpu CPU (AMD Ryzen 7 5800H with Radeon Graphics)\n",
            "Setup complete  (16 CPUs, 15.4 GB RAM, 511.6/642.9 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnnZSm5OQfPQ"
      },
      "source": [
        "## CLI Basics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K33S7zlkQku0"
      },
      "source": [
        "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://v8docs.ultralytics.com/cli/).\n",
        "\n",
        "```\n",
        "yolo task=detect    mode=train    model=yolov8n.yaml      args...\n",
        "          classify       predict        yolov8n-cls.yaml  args...\n",
        "          segment        val            yolov8n-seg.yaml  args...\n",
        "                         export         yolov8n.pt        format=onnx  args...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with Pre-trained COCO Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1qD4toTTw0"
      },
      "source": [
        "### üíª CLI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaE1kLS8R4CV"
      },
      "source": [
        "`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDbMt_M6PiXb",
        "outputId": "db49b609-cfb3-4773-e4e6-81614d111b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\asus\\Downloads\\CarDamage\\code\\model\\Dataset\\Dataset\\data\\images\\val\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.28 üöÄ Python-3.12.0 torch-2.5.0+cpu CPU (AMD Ryzen 7 5800H with Radeon Graphics)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n",
            "image 1/1 C:\\Users\\asus\\Downloads\\CarDamage\\code\\model\\Dataset\\Dataset\\data\\images\\val\\dog.jpeg: 640x384 1 person, 1 car, 1 dog, 281.9ms\n",
            "Speed: 11.6ms preprocess, 281.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(file, map_location=\"cpu\")\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "LyopYpK1TQrB"
      },
      "outputs": [],
      "source": [
        "# %cd {HOME}\n",
        "# Image(filename='runs/detect/predict/dog.jpeg', height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFMBYQtMVL-B"
      },
      "source": [
        "### üêç Python SDK\n",
        "\n",
        "The simplest way of simply using YOLOv8 directly in a Python environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx9NWF-sVN6Y",
        "outputId": "42c68241-8b5a-4597-d5f0-e6a7867f4a79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(file, map_location=\"cpu\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n",
            "image 1/1 C:\\Users\\asus\\Downloads\\CarDamage\\code\\model\\Dataset\\Dataset\\data\\images\\val\\dog.jpeg: 640x384 1 person, 1 car, 1 dog, 210.3ms\n",
            "Speed: 3.5ms preprocess, 210.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(f'{HOME}/yolov8n.pt')\n",
        "results = model.predict(source='https://media.roboflow.com/notebooks/examples/dog.jpeg', conf=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAi4PvrItTCf",
        "outputId": "6d5e0223-b5ad-4b40-8094-854c7c6c4e63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   0.0000,  314.4714,  625.0755, 1278.1946],\n",
              "        [  55.1731,  250.0220,  648.1080, 1266.2720],\n",
              "        [ 633.2290,  719.5391,  701.0540,  786.0336]])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results[0].boxes.xyxy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqT2M01K1LUb",
        "outputId": "a33586ac-fe54-48a3-f52e-675a3197e13e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.7271, 0.2907, 0.2846])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results[0].boxes.conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKIwJ5yw1PMb",
        "outputId": "e31f0368-787e-4749-81bb-2c0a636026d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0., 16.,  2.])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results[0].boxes.cls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_di00JWpOX8",
        "outputId": "e5dd734d-7a62-4b11-a46b-ebbd6ad8d669"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hadnMgv2pahh",
        "outputId": "fa0dd8af-4ba5-4573-d2a1-a070f97a63fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\asus\\Downloads\\CarDamage\\code\\model\\Dataset\\Dataset\\data\\images\\val\n",
            "C:\\Users\\asus\\Downloads\\CarDamage\\code\\model\\Dataset\\Dataset\\data\\images\\val\n"
          ]
        }
      ],
      "source": [
        "%cd C:\\Users\\asus\\Downloads\\CarDamage\\code\\model\\Dataset\\Dataset\\data\\images\\val\n",
        "\n",
        "%cd C:\\Users\\asus\\Downloads\\CarDamage\\code\\model\\Dataset\\Dataset\\data\\images\\val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2YkphuiaE7_",
        "outputId": "41f751df-c3d2-40ab-8911-1075d953a88d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\asus\\Downloads\\CarDamage\\code\\model\\Dataset\\Dataset\\data\\images\\train\n",
            "New https://pypi.org/project/ultralytics/8.3.105 available üòÉ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.28 üöÄ Python-3.12.0 torch-2.5.0+cpu CPU (AMD Ryzen 7 5800H with Radeon Graphics)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(file, map_location=\"cpu\")\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 517, in get_dataset\n",
            "    data = check_det_dataset(self.args.data)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 269, in check_det_dataset\n",
            "    file = check_file(dataset)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 510, in check_file\n",
            "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
            "FileNotFoundError: 'data.yaml' does not exist\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
            "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 583, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 655, in train\n",
            "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 130, in __init__\n",
            "    self.trainset, self.testset = self.get_dataset()\n",
            "                                  ^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 521, in get_dataset\n",
            "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error ‚ùå {e}\")) from e\n",
            "RuntimeError: Dataset 'data.yaml' error  'data.yaml' does not exist\n"
          ]
        }
      ],
      "source": [
        "%cd C:\\Users\\asus\\Downloads\\CarDamage\\code\\model\\Dataset\\Dataset\\data\\images\\train\n",
        "!yolo task=detect mode=train model=yolov8s.pt data = data.yaml epochs=100 imgsz=224 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MScstfHhArr",
        "outputId": "6234125f-cc5e-4d76-d3c6-ae9c60ef7ba2"
      },
      "outputs": [],
      "source": [
        "# !ls runs/detect/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "_J35i8Ofhjxa",
        "outputId": "1e55f36d-94db-4ff7-a0ae-2e43e4c076fb"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'runs/detect/train7/confusion_matrix.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruns/detect/train7/confusion_matrix.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
            "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
            "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/detect/train7/confusion_matrix.png'"
          ]
        }
      ],
      "source": [
        "Image(filename='runs/detect/train7/confusion_matrix.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "A-urTWUkhRmn",
        "outputId": "b3f539d3-8cff-4d9b-928c-6c6d3cc11b93"
      },
      "outputs": [],
      "source": [
        "Image(filename='C:\\Users\\IT Support\\Downloads\\yolov8\\YOLO-v8-Object-Detection-main\\yolo-V8\\runs\\detect\\train7\\results.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "HI4nADCCj3F5",
        "outputId": "0f7f34bf-b1a5-4771-ddd4-e76155f3659f"
      },
      "outputs": [],
      "source": [
        "Image(filename='runs/detect/train6/val_batch0_pred.jpg', width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODk1VTlevxn"
      },
      "source": [
        "## Validate Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyuwrNlXc1P",
        "outputId": "45b46859-ecb4-4c2c-d1f5-ed23f8d703ee"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=val model=runs/detect/train2/weights/best.pt data=data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjc1ctZykYuf",
        "outputId": "b722bbbe-ece3-4b91-f804-5fc3798d1210"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=predict model=runs/detect/train2/weights/best.pt conf=0.25 source=data/test/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYIo95n-I0S"
      },
      "source": [
        "**NOTE:** Let's take a look at few results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbVjEtPAkz3j"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for image_path in glob.glob('runs/detect/predict/*.jpg')[:3]:\n",
        "      display(Image(filename=image_path, width=600))\n",
        "      print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
